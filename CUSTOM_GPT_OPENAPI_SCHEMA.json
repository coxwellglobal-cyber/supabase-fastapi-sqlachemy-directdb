from fastapi import FastAPI, HTTPException, Request, status
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

from pydantic import BaseModel, Field
from sqlalchemy import create_engine, text, event
from sqlalchemy.exc import SQLAlchemyError

import logging
import os
import re
import time
import uuid
from typing import Any, Dict, List, Optional, Tuple

from slowapi import Limiter
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from slowapi.middleware import SlowAPIMiddleware

# Optional dotenv (ONLY for local)
try:
    from dotenv import load_dotenv
except Exception:
    load_dotenv = None

# ----------------------------
# CONFIG / LOGGING
# ----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("COXWELL_AI_BACKEND")

# Load environment variables locally (Render uses dashboard env vars)
if os.getenv("RENDER") is None and load_dotenv is not None:
    load_dotenv()

# ----------------------------
# REQUIRED ENV VARS
# ----------------------------
DATABASE_URL = os.getenv("DATABASE_URL")
REX_API_KEY = os.getenv("REX_API_KEY")

# Optional env vars
RATE_LIMIT = os.getenv("RATE_LIMIT", "100/hour")
STATEMENT_TIMEOUT_MS = int(os.getenv("STATEMENT_TIMEOUT_MS", "8000"))  # 8s default
CORS_ALLOW_ORIGINS = os.getenv("CORS_ALLOW_ORIGINS", "*")  # set to comma-separated domains in prod

if not DATABASE_URL:
    logger.error("DATABASE_URL environment variable is not set")
    raise ValueError("DATABASE_URL environment variable is required")

if not REX_API_KEY:
    logger.error("REX_API_KEY environment variable is not set")
    raise ValueError("REX_API_KEY environment variable is required")

logger.info(f"RATE_LIMIT = {RATE_LIMIT}")
logger.info(f"STATEMENT_TIMEOUT_MS = {STATEMENT_TIMEOUT_MS}")
logger.info(f"CORS_ALLOW_ORIGINS = {CORS_ALLOW_ORIGINS}")

# ----------------------------
# DB SCOPE (LOCKED VIEW ONLY)
# ----------------------------
ALLOWED_VIEW = "public.v_product_intelligence"
ALLOWED_COLUMNS = {"id", "product_name", "thickness", "product_class", "color", "finish"}

# ----------------------------
# AUTH
# ----------------------------
def require_api_key(api_key: str) -> None:
    if api_key != REX_API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")

# ----------------------------
# REQUEST / RESPONSE MODELS
# ----------------------------
class AiQueryRequest(BaseModel):
    api_key: str
    question: str = Field(..., min_length=1, max_length=500)
    limit: int = Field(default=50, ge=1, le=100)

class AiQueryResponse(BaseModel):
    request_id: str
    status: str
    question: str
    row_limit: int
    row_count: int
    interpreted_filters: Dict[str, Any]
    warnings: List[str]
    latency_ms: int
    rows: List[Dict[str, Any]]

# ----------------------------
# INTENT PARSER (SAFE / ALLOWLIST)
# ----------------------------
THICKNESS_RE = re.compile(r"\b(\d{1,3})\s*(mm|mil|millimeter|millimetre)?\b", re.IGNORECASE)

def parse_intent(question: str) -> Tuple[Dict[str, Any], List[str]]:
    """
    Extract ONLY allowed filters from natural language.
    This is conservative by design.
    """
    q = question.strip().lower()
    filters: Dict[str, Any] = {}
    warnings: List[str] = []

    # thickness (e.g. "25mm", "25 mm")
    m = THICKNESS_RE.search(q)
    if m:
        try:
            thickness_val = int(m.group(1))
            # only accept realistic thickness ranges
            if 1 <= thickness_val <= 100:
                filters["thickness"] = thickness_val
        except Exception:
            pass

    # product_class (simple keyword mapping)
    # You can expand this mapping as your dataset grows.
    product_class_map = {
        "multicell": "multicell",
        "multiwall": "multicell",
        "corrugated": "corrugated",
        "solid": "solid",
        "snapwall": "snapwall",
        "vivid": "vivid"
    }
    for key, val in product_class_map.items():
        if key in q:
            filters["product_class"] = val
            break

    # color (basic keyword capture) - keep conservative
    color_keywords = ["clear", "opal", "bronze", "blue", "green", "red", "yellow", "smoke", "grey", "gray"]
    for ck in color_keywords:
        if re.search(rf"\b{re.escape(ck)}\b", q):
            filters["color"] = ck
            break

    # finish (basic)
    finish_keywords = ["uv", "matte", "glossy", "embossed", "textured"]
    for fk in finish_keywords:
        if re.search(rf"\b{re.escape(fk)}\b", q):
            filters["finish"] = fk
            break

    # if no structured filters found, we do a safe name search
    # (tokenize into words, remove very short/common words)
    if not filters:
        warnings.append("No structured filters detected; using product_name search.")
        tokens = [t for t in re.split(r"[^a-z0-9]+", q) if len(t) >= 3]
        tokens = [t for t in tokens if t not in {"show", "all", "list", "give", "with", "from", "that", "this", "polycarbonate", "products"}]
        if tokens:
            filters["product_name_tokens"] = tokens
        else:
            warnings.append("Question too generic; returning top results.")

    return filters, warnings

# ----------------------------
# SQL BUILDER (SAFE)
# ----------------------------
def build_safe_sql(filters: Dict[str, Any], limit: int) -> Tuple[str, Dict[str, Any]]:
    """
    Build parameterized SQL against ONLY the allowed view.
    No user SQL is accepted.
    """
    where_clauses: List[str] = []
    params: Dict[str, Any] = {"limit": limit}

    # thickness exact match
    if "thickness" in filters:
        where_clauses.append("thickness = :thickness")
        params["thickness"] = filters["thickness"]

    # product_class partial match (ILIKE)
    if "product_class" in filters:
        where_clauses.append("product_class ILIKE :product_class")
        params["product_class"] = f"%{filters['product_class']}%"

    # color partial match
    if "color" in filters:
        where_clauses.append("color ILIKE :color")
        params["color"] = f"%{filters['color']}%"

    # finish partial match
    if "finish" in filters:
        where_clauses.append("finish ILIKE :finish")
        params["finish"] = f"%{filters['finish']}%"

    # product_name token match (AND all tokens)
    if "product_name_tokens" in filters:
        tokens = filters["product_name_tokens"]
        for i, tok in enumerate(tokens[:5]):  # cap to 5 tokens for performance
            key = f"pn{i}"
            where_clauses.append(f"product_name ILIKE :{key}")
            params[key] = f"%{tok}%"

    where_sql = ""
    if where_clauses:
        where_sql = "WHERE " + " AND ".join(where_clauses)

    # Select only allowed columns
    sql = f"""
        SELECT id, product_name, thickness, product_class, color, finish
        FROM {ALLOWED_VIEW}
        {where_sql}
        ORDER BY id
        LIMIT :limit
    """
    return sql, params

# ----------------------------
# FASTAPI APP
# ----------------------------
app = FastAPI(title="Coxwell AI Data Backbone", version="1.0.0")

# CORS
if CORS_ALLOW_ORIGINS.strip() == "*":
    allow_origins = ["*"]
else:
    allow_origins = [o.strip() for o in CORS_ALLOW_ORIGINS.split(",") if o.strip()]

app.add_middleware(
    CORSMiddleware,
    allow_origins=allow_origins,
    allow_credentials=True,
    allow_methods=["POST", "GET", "OPTIONS"],
    allow_headers=["*"],
)

# Rate limiting (SlowAPI)
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_middleware(SlowAPIMiddleware)

@app.exception_handler(RateLimitExceeded)
async def custom_rate_limit_exceeded_handler(request: Request, exc: RateLimitExceeded) -> JSONResponse:
    return JSONResponse(
        status_code=status.HTTP_429_TOO_MANY_REQUESTS,
        content={"detail": "Rate limit exceeded. Please try again later."}
    )

# ----------------------------
# SQLAlchemy Engine (read-only + timeouts)
# ----------------------------
engine = create_engine(DATABASE_URL, pool_pre_ping=True)

@event.listens_for(engine, "connect")
def set_session_safety(dbapi_connection, connection_record):
    """
    Enforce read-only at the session level and set timeouts.
    """
    try:
        # psycopg2 connection supports set_session
        dbapi_connection.set_session(readonly=True, autocommit=False)
    except Exception as e:
        logger.warning(f"Failed to set DB session to readonly: {e}")

    try:
        # Set DB-side statement timeout for safety
        cur = dbapi_connection.cursor()
        cur.execute(f"SET statement_timeout = '{STATEMENT_TIMEOUT_MS}ms'")
        cur.execute("SET idle_in_transaction_session_timeout = '8000ms'")
        # Defense-in-depth
        cur.execute("SET default_transaction_read_only = on")
        cur.close()
    except Exception as e:
        logger.warning(f"Failed to set session timeouts/read-only flags: {e}")

# ----------------------------
# ENDPOINTS
# ----------------------------
@app.get("/health")
async def health() -> Dict[str, str]:
    return {"status": "ok", "service": "coxwell-ai-backend"}

@app.post("/ai_query", response_model=AiQueryResponse)
@limiter.limit(lambda: RATE_LIMIT)
async def ai_query(payload: AiQueryRequest, request: Request) -> AiQueryResponse:
    """
    Accepts AI intent (question), NOT raw SQL.
    Converts intent to a safe, parameterized query against ONLY public.v_product_intelligence.
    """
    start = time.time()
    request_id = f"aiq_{uuid.uuid4().hex[:12]}"

    require_api_key(payload.api_key)

    filters, warnings = parse_intent(payload.question)
    sql, params = build_safe_sql(filters, payload.limit)

    logger.info(f"[{request_id}] intent='{payload.question}' filters={filters}")

    try:
        with engine.connect() as conn:
            # Extra safety inside request (defense-in-depth)
            conn.exec_driver_sql("SET default_transaction_read_only = on")
            conn.exec_driver_sql(f"SET statement_timeout = '{STATEMENT_TIMEOUT_MS}ms'")

            result = conn.execute(text(sql), params)
            rows = [dict(r._mapping) for r in result.fetchall()]

        latency_ms = int((time.time() - start) * 1000)

        return AiQueryResponse(
            request_id=request_id,
            status="ok",
            question=payload.question,
            row_limit=payload.limit,
            row_count=len(rows),
            interpreted_filters=filters,
            warnings=warnings,
            latency_ms=latency_ms,
            rows=rows
        )

    except SQLAlchemyError as e:
        logger.error(f"[{request_id}] Database error: {str(e)}")
        raise HTTPException(status_code=500, detail="Database error")
    except Exception as e:
        logger.error(f"[{request_id}] Unexpected error: {str(e)}")
        raise HTTPException(status_code=500, detail="Unexpected server error")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
