from fastapi import FastAPI, HTTPException, Request, status
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

from sqlalchemy import create_engine, text, event
from sqlalchemy.exc import SQLAlchemyError

import logging
import os
from typing import Any, Dict, List

import psycopg2
from psycopg2.extras import RealDictCursor

from slowapi import Limiter
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from slowapi.middleware import SlowAPIMiddleware

# Optional monitoring middleware (won't crash if not installed)
try:
    from tigzig_api_monitor import APIMonitorMiddleware
except Exception:
    APIMonitorMiddleware = None

# Optional dotenv (ONLY for local)
try:
    from dotenv import load_dotenv
except Exception:
    load_dotenv = None


# ----------------------------
# CONFIG / LOGGING
# ----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("SUPABASE_CONNECT_FASTAPI")


# Load environment variables locally (Render uses dashboard env vars)
if os.getenv("RENDER") is None and load_dotenv is not None:
    load_dotenv()


# ----------------------------
# REQUIRED ENV VARS
# ----------------------------
DATABASE_URL = os.getenv("DATABASE_URL")
REX_API_KEY = os.getenv("REX_API_KEY")

# Optional env vars
RATE_LIMIT = os.getenv("RATE_LIMIT", "100/hour")
ENABLE_MONITOR = os.getenv("ENABLE_MONITOR", "true").lower() == "true"

if not DATABASE_URL:
    logger.error("DATABASE_URL environment variable is not set")
    raise ValueError("DATABASE_URL environment variable is required")

if not REX_API_KEY:
    logger.error("REX_API_KEY environment variable is not set")
    raise ValueError("REX_API_KEY environment variable is required")

logger.info(f"RATE_LIMIT = {RATE_LIMIT}")
logger.info(f"ENABLE_MONITOR = {ENABLE_MONITOR}")


# ----------------------------
# TABLE SCOPE (your Supabase table)
# ----------------------------
ALLOWED_TABLE = 'public."Product_Intelligence_For_Supabase"'


# ----------------------------
# SQL SAFETY RULES
# ----------------------------
DISALLOWED_KEYWORDS = (
    "insert", "update", "delete", "drop", "alter", "create", "truncate",
    "grant", "revoke", "comment", "vacuum", "analyze", "call", "do",
    "copy", "execute", "refresh", "transaction", "select for update", "for update"
)

AGG_HINTS = (
    " group by ", " having ", " count(", " sum(", " min(", " max(",
    " avg(", " distinct "
)


def _normalize_sql(sql: str) -> str:
    """Normalize whitespace and remove trailing semicolon."""
    return " ".join(sql.strip().split()).rstrip(";")


def _block_multistatement(sql: str) -> None:
    s = sql.strip()
    if ";" in s.rstrip(";"):
        raise HTTPException(
            status_code=400,
            detail="Multi-statement SQL is not allowed."
        )


def _only_select(sql: str) -> None:
    if not sql.strip().lower().startswith("select"):
        raise HTTPException(
            status_code=400,
            detail="Only SELECT queries are allowed."
        )


def _block_dangerous_keywords(sql: str) -> None:
    s = f" {_normalize_sql(sql).lower()} "
    for kw in DISALLOWED_KEYWORDS:
        if f" {kw} " in s or kw in s:
            raise HTTPException(
                status_code=400,
                detail=f"Disallowed keyword detected: {kw}"
            )


def _must_use_allowed_table(sql: str) -> None:
    s = _normalize_sql(sql).lower()
    allowed1 = 'public."product_intelligence_for_supabase"'
    allowed2 = "public.product_intelligence_for_supabase"

    if allowed1 not in s and allowed2 not in s:
        raise HTTPException(
            status_code=400,
            detail=f"Query must use only this table: {ALLOWED_TABLE}"
        )


def _is_aggregation(sql: str) -> bool:
    s = f" {_normalize_sql(sql).lower()} "
    return any(hint in s for hint in AGG_HINTS)


def _enforce_limit_100(sql: str) -> str:
    s = _normalize_sql(sql)
    s_low = f" {s.lower()} "

    if " limit " in s_low:
        return s

    if _is_aggregation(s):
        return s

    return f"{s} LIMIT 100"


def validate_and_prepare_sql(sqlquery: str) -> str:
    _block_multistatement(sqlquery)
    _only_select(sqlquery)
    _block_dangerous_keywords(sqlquery)
    _must_use_allowed_table(sqlquery)
    return _enforce_limit_100(sqlquery)


# ----------------------------
# AUTH
# ----------------------------
def require_api_key(api_key: str) -> None:
    if api_key != REX_API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")


# ----------------------------
# FASTAPI APP
# ----------------------------
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_middleware(SlowAPIMiddleware)


@app.exception_handler(RateLimitExceeded)
async def rate_limit_handler(request: Request, exc: RateLimitExceeded):
    return JSONResponse(
        status_code=status.HTTP_429_TOO_MANY_REQUESTS,
        content={"detail": "Rate limit exceeded. Please try again later."},
    )


if ENABLE_MONITOR and APIMonitorMiddleware is not None:
    app.add_middleware(
        APIMonitorMiddleware,
        app_name="SUPABASE_CONNECT_FASTAPI",
        include_prefixes=("/sqlquery_alchemy/", "/sqlquery_direct/"),
    )
else:
    logger.info("APIMonitorMiddleware disabled or not installed.")


# ----------------------------
# SQLAlchemy Engine (read-only)
# ----------------------------
engine = create_engine(DATABASE_URL, pool_pre_ping=True)


@event.listens_for(engine, "connect")
def set_session_readonly(dbapi_connection, connection_record):
    try:
        dbapi_connection.set_session(readonly=True, autocommit=False)
    except Exception as e:
        logger.warning(f"Failed to set readonly session: {e}")


# ----------------------------
# ENDPOINTS
# ----------------------------
@app.get("/health")
async def health():
    return {"status": "ok"}


@app.get("/sqlquery_alchemy/")
@limiter.limit(lambda: RATE_LIMIT)
async def sqlquery_alchemy(
    sqlquery: str,
    api_key: str,
    request: Request
) -> List[Dict[str, Any]]:

    require_api_key(api_key)
    prepared_sql = validate_and_prepare_sql(sqlquery)

    try:
        with engine.connect() as connection:
            trans = connection.begin()
            connection.exec_driver_sql("SET TRANSACTION READ ONLY")
            result = connection.execute(text(prepared_sql))

            rows = result.fetchall()
            columns = result.keys()

            trans.commit()
            return [dict(zip(columns, row)) for row in rows]

    except SQLAlchemyError as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/sqlquery_direct/")
@limiter.limit(lambda: RATE_LIMIT)
async def sqlquery_direct(
    sqlquery: str,
    api_key: str,
    request: Request
) -> List[Dict[str, Any]]:

    require_api_key(api_key)
    prepared_sql = validate_and_prepare_sql(sqlquery)

    conn = None
    try:
        conn = psycopg2.connect(
            DATABASE_URL,
            cursor_factory=RealDictCursor
        )
        conn.set_session(readonly=True, autocommit=False)

        with conn.cursor() as cursor:
            cursor.execute(prepared_sql)
            return cursor.fetchall()

    finally:
        if conn:
            conn.close()


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
