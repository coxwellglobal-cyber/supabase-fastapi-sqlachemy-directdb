from fastapi import FastAPI, HTTPException, Request, status
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

from sqlalchemy import create_engine, text, event
from sqlalchemy.exc import SQLAlchemyError

import logging
import os
from typing import Any, Dict, List

import psycopg2
from psycopg2.extras import RealDictCursor

from slowapi import Limiter
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from slowapi.middleware import SlowAPIMiddleware

# Optional monitoring middleware (won't crash if not installed)
try:
    from tigzig_api_monitor import APIMonitorMiddleware
except Exception:
    APIMonitorMiddleware = None

# Optional dotenv (ONLY for local)
try:
    from dotenv import load_dotenv
except Exception:
    load_dotenv = None


# ----------------------------
# CONFIG / LOGGING
# ----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("SUPABASE_CONNECT_FASTAPI")

# Load environment variables locally (Render uses dashboard env vars)
if os.getenv("RENDER") is None and load_dotenv is not None:
    load_dotenv()


# ----------------------------
# REQUIRED ENV VARS
# ----------------------------
DATABASE_URL = os.getenv("DATABASE_URL")
REX_API_KEY = os.getenv("REX_API_KEY")

# Optional env vars
RATE_LIMIT = os.getenv("RATE_LIMIT", "100/hour")
ENABLE_MONITOR = os.getenv("ENABLE_MONITOR", "true").lower() == "true"

if not DATABASE_URL:
    logger.error("DATABASE_URL environment variable is not set")
    raise ValueError("DATABASE_URL environment variable is required")

if not REX_API_KEY:
    logger.error("REX_API_KEY environment variable is not set")
    raise ValueError("REX_API_KEY environment variable is required")

logger.info(f"RATE_LIMIT = {RATE_LIMIT}")
logger.info(f"ENABLE_MONITOR = {ENABLE_MONITOR}")


# ----------------------------
# TABLE SCOPE (your Supabase table)
# ----------------------------
# Enforce that every query must reference this table only:
ALLOWED_TABLE = 'public."Product_Intelligence_For_Supabase"'


# ----------------------------
# SQL SAFETY RULES
# ----------------------------
DISALLOWED_KEYWORDS = (
    "insert", "update", "delete", "drop", "alter", "create", "truncate",
    "grant", "revoke", "comment", "vacuum", "analyze", "call", "do",
    "copy", "execute", "refresh", "transaction",
    "select for update", "for update"
)

AGG_HINTS = (
    " group by ",
    " having ",
    " count(",
    " sum(",
    " min(",
    " max(",
    " avg(",
    " distinct "
)

def _normalize_sql(sql: str) -> str:
    """Normalize whitespace and remove a trailing semicolon."""
    return " ".join(sql.strip().split()).rstrip(";")

def _block_multistatement(sql: str) -> None:
    """Block multi-statement queries like: SELECT 1; DROP TABLE ..."""
    s = sql.strip()
    if ";" in s.rstrip(";"):
        raise HTTPException(status_code=400, detail="Multi-statement SQL is not allowed.")

def _only_select(sql: str) -> None:
    """Only allow SELECT queries."""
    s = sql.strip().lower()
    if not s.startswith("select"):
        raise HTTPException(status_code=400, detail="Only SELECT queries are allowed.")

def _block_dangerous_keywords(sql: str) -> None:
    s = f" {_normalize_sql(sql).lower()} "
    for kw in DISALLOWED_KEYWORDS:
        if f" {kw} " in s or kw in s:
            raise HTTPException(status_code=400, detail=f"Disallowed keyword detected: {kw}")

def _must_use_allowed_table(sql: str) -> None:
    """
    Enforce query scope: must reference the allowed table.
    Allow quoted or unquoted versions.
    """
    s = _normalize_sql(sql).lower()
    allowed1 = 'public."product_intelligence_for_supabase"'
    allowed2 = "public.product_intelligence_for_supabase"
    if (allowed1 not in s) and (allowed2 not in s):
        raise HTTPException(
            status_code=400,
            detail=f"Query must use only this table: {ALLOWED_TABLE}"
        )

def _is_aggregation(sql: str) -> bool:
    s = f" {_normalize_sql(sql).lower()} "
    return any(hint in s for hint in AGG_HINTS)

def _enforce_limit_100(sql: str) -> str:
    """
    Rule:
    - If retrieving rows, append LIMIT 100 (if no LIMIT already)
    - If aggregation, do NOT add LIMIT
    """
    s = _normalize_sql(sql)
    s_low = f" {s.lower()} "

    if " limit " in s_low:
        return s

    if _is_aggregation(s):
        return s

    return f"{s} LIMIT 100"

def validate_and_prepare_sql(sqlquery: str) -> str:
    _block_multistatement(sqlquery)
    _only_select(sqlquery)
    _block_dangerous_keywords(sqlquery)
    _must_use_allowed_table(sqlquery)
    return _enforce_limit_100(sqlquery)


# ----------------------------
# AUTH
# ----------------------------
def require_api_key(api_key: str) -> None:
    if api_key != REX_API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")


# ----------------------------
# FASTAPI APP
# ----------------------------
app = FastAPI()

# CORS (ok for testing; restrict in production)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Rate limiting (SlowAPI)
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_middleware(SlowAPIMiddleware)

@app.exception_handler(RateLimitExceeded)
async def custom_rate_limit_exceeded_handler(request: Request, exc: RateLimitExceeded) -> JSONResponse:
    return JSONResponse(
        status_code=status.HTTP_429_TOO_MANY_REQUESTS,
        content={"detail": "Rate limit exceeded. Please try again later."}
    )

# Optional monitoring middleware
if ENABLE_MONITOR and APIMonitorMiddleware is not None:
    app.add_middleware(
        APIMonitorMiddleware,
        app_name="SUPABASE_CONNECT_FASTAPI",
        include_prefixes=("/sqlquery_alchemy/", "/sqlquery_direct/")
    )
else:
    logger.info("APIMonitorMiddleware disabled or not installed.")


# ----------------------------
# SQLAlchemy Engine (read-only)
# ----------------------------
engine = create_engine(DATABASE_URL, pool_pre_ping=True)

@event.listens_for(engine, "connect")
def set_session_readonly(dbapi_connection, connection_record):
    """
    Enforce read-only at the PostgreSQL session level (SQLAlchemy).
    """
    try:
        dbapi_connection.set_session(readonly=True, autocommit=False)
        logger.debug("SQLAlchemy DBAPI session set to readonly")
    except Exception as e:
        logger.warning(f"Failed to set SQLAlchemy session to readonly: {e}")


# ----------------------------
# ENDPOINTS
# ----------------------------
@app.get("/health")
async def health() -> Dict[str, str]:
    return {"status": "ok"}


@app.get("/sqlquery_alchemy/")
@limiter.limit(lambda: RATE_LIMIT)
async def sqlquery_alchemy(sqlquery: str, api_key: str, request: Request) -> List[Dict[str, Any]]:
    """
    Execute SQL query using SQLAlchemy and return results directly.
    Enforced:
    - Single SELECT only
    - Must query public."Product_Intelligence_For_Supabase"
    - LIMIT 100 auto for row fetches (no LIMIT for aggregation)
    - DB-level read-only transaction
    """
    require_api_key(api_key)

    prepared_sql = validate_and_prepare_sql(sqlquery)
    logger.info(f"[ALCHEMY] {prepared_sql}")

    try:
        with engine.connect() as connection:
            trans = connection.begin()
            try:
                connection.exec_driver_sql("SET TRANSACTION READ ONLY")

                result = connection.execute(text(prepared_sql))
                columns = result.keys()
                rows = result.fetchall()

                results = [dict(zip(columns, row)) for row in rows]
                trans.commit()
                return results
            except Exception:
                trans.rollback()
                raise

    except HTTPException:
        raise
    except SQLAlchemyError as e:
        logger.error(f"SQLAlchemy error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")
    except Exception as e:
        logger.error(f"Unexpected error in SQLAlchemy endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Unexpected error: {str(e)}")


@app.get("/sqlquery_direct/")
@limiter.limit(lambda: RATE_LIMIT)
async def sqlquery_direct(sqlquery: str, api_key: str, request: Request) -> List[Dict[str, Any]]:
    """
    Execute SQL query using direct psycopg2 connection and return results.
    Uses DATABASE_URL directly (IMPORTANT for passwords with special characters).
    Enforced:
    - Single SELECT only
    - Must query public."Product_Intelligence_For_Supabase"
    - LIMIT 100 auto for row fetches (no LIMIT for aggregation)
    - DB session read-only
    """
    require_api_key(api_key)

    prepared_sql = validate_and_prepare_sql(sqlquery)
    logger.info(f"[DIRECT] {prepared_sql}")

    connection = None
    try:
        connection = psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)
        connection.set_session(readonly=True, autocommit=False)

        with connection.cursor() as cursor:
            cursor.execute(prepared_sql)
            results = cursor.fetchall()
            return list(results)

    except HTTPException:
        raise
    except psycopg2.Error as e:
        logger.error(f"PostgreSQL error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")
    except Exception as e:
        logger.error(f"Unexpected error in direct endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Unexpected error: {str(e)}")
    finally:
        if connection:
            connection.close()
            logger.debug("Database connection closed")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
